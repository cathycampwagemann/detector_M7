{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of_2DH1fPZUG"
      },
      "outputs": [],
      "source": [
        "import torch # Si importo sólo los módulos, me sale error\n",
        "import os # Si importo sólo los módulos, me sale error\n",
        "import cv2 # Si importo sólo los módulos, me sale error\n",
        "import numpy as np # Si importo sólo los módulos, me sale error\n",
        "from numpy import array, ndarray, squeeze\n",
        "from PIL import Image, ImageOps\n",
        "from pandas import DataFrame, read_csv\n",
        "from os import listdir, path\n",
        "from os.path import isdir, join, isfile, dirname\n",
        "from cv2 import imread, imwrite, resize, cvtColor, COLOR_BGR2GRAY\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models, transforms\n",
        "from collections import OrderedDict\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defino las funciones individuales\n",
        "\n",
        "def construir_ruta_imagen(nombre_imagen, carpeta_principal_imagenes, subcarpeta=None, categoria=None):\n",
        "    if subcarpeta and categoria:\n",
        "        return os.path.join(carpeta_principal_imagenes, subcarpeta, categoria, nombre_imagen)\n",
        "    elif subcarpeta:\n",
        "        return os.path.join(carpeta_principal_imagenes, subcarpeta, nombre_imagen)\n",
        "    else:\n",
        "        return os.path.join(carpeta_principal_imagenes, nombre_imagen)\n",
        "\n",
        "def nuevo_alto_deseado(imagen):\n",
        "    alto_original, ancho_original, _ = imagen.shape\n",
        "    if alto_original<670:\n",
        "      nuevo_alto_deseado = 447\n",
        "    elif alto_original>1200:\n",
        "      nuevo_alto_deseado = 1440\n",
        "    else:\n",
        "      nuevo_alto_deseado = 800\n",
        "    return nuevo_alto_deseado\n",
        "\n",
        "def redimensionar_imagenes(imagen, nuevo_alto_deseado):\n",
        "    alto_original, ancho_original, _ = imagen.shape\n",
        "    nuevo_alto_deseado =  nuevo_alto_deseado(imagen)\n",
        "    factor_redimensionamiento = nuevo_alto_deseado / alto_original\n",
        "    nuevo_ancho = int(ancho_original * factor_redimensionamiento)\n",
        "    imagen_redimensionada = cv2.resize(imagen, (nuevo_ancho, nuevo_alto_deseado))\n",
        "    return imagen_redimensionada\n",
        "\n",
        "\n",
        "def convertir_a_modo_L(imagen):\n",
        "    if isinstance(imagen, np.ndarray):\n",
        "        imagen_pil = Image.fromarray(imagen)\n",
        "        imagen_gris = imagen_pil.convert(\"L\")\n",
        "        return np.array(imagen_gris)\n",
        "\n",
        "def add_padding(image, target_size=1440):\n",
        "    ancho, alto = image.size\n",
        "    alto, ancho = torch.tensor(alto), torch.tensor(ancho)  # Convertir a tensores de PyTorch\n",
        "    padding_vertical = max((target_size - alto) // 2, torch.tensor(0))\n",
        "    padding_horizontal = max((target_size - ancho) // 2, torch.tensor(0))\n",
        "    imagen_con_padding = ImageOps.expand(image, (padding_horizontal, padding_vertical, padding_horizontal, padding_vertical), fill=0)\n",
        "    imagen_con_padding = imagen_con_padding.resize((target_size, target_size))\n",
        "    return imagen_con_padding\n",
        "\n",
        "def procesar_imagen_padding(image_paths, output_directory):\n",
        "    nuevas_rutas = []\n",
        "    max_size = 1440\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        imagen = Image.open(image_path)\n",
        "        imagen_con_padding = add_padding(imagen, max_size)\n",
        "        imagen_con_padding.save(image_path)  # Sobrescribir la imagen original con la versión con padding\n",
        "        nuevas_rutas.append(image_path)\n",
        "    return nuevas_rutas\n",
        "\n",
        "def redimensionar_imagenes_con_padding(image_paths, nuevo_alto=720, nuevo_ancho=720):\n",
        "\n",
        "    nuevas_rutas2 = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        imagen = cv2.imread(image_path)\n",
        "        if imagen is not None:\n",
        "            imagen_redimensionada = cv2.resize(imagen, (nuevo_ancho, nuevo_alto))\n",
        "            cv2.imwrite(image_path, imagen_redimensionada)\n",
        "            nuevas_rutas2.append(image_path)\n",
        "    return nuevas_rutas2\n",
        "\n",
        "def normalizar_imagenes(ruta):\n",
        "    imagen = load_img(ruta)\n",
        "    imagen = imagen.convert(\"L\")\n",
        "    imagen_array = img_to_array(imagen)\n",
        "    imagen_normalizada = imagen_array / 255.0\n",
        "    return imagen_normalizada\n",
        "\n",
        "def procesar_imagen(nombre_imagen, carpeta_principal_imagenes):\n",
        "    ruta_imagen = construir_ruta_imagen(nombre_imagen, carpeta_principal_imagenes)\n",
        "    carpeta_imagen_original = os.path.dirname(ruta_imagen)\n",
        "    imagen = cv2.imread(ruta_imagen)\n",
        "    imagen_redimensionada = redimensionar_imagenes(imagen, nuevo_alto_deseado)\n",
        "    imagen_gris = convertir_a_modo_L(imagen_redimensionada)\n",
        "    ruta_imagen_gris=cv2.imwrite(ruta_imagen,imagen_gris)\n",
        "    imagen_con_padding = procesar_imagen_padding([ruta_imagen], carpeta_imagen_original)\n",
        "    imagen_redimensionada2 = redimensionar_imagenes_con_padding(imagen_con_padding, nuevo_alto=720, nuevo_ancho=720)\n",
        "    imagen_normalizada = normalizar_imagenes(ruta_imagen)\n",
        "    imagen_normalizada_squeezed = np.squeeze(imagen_normalizada, axis=2)\n",
        "    imagen_tensor = torch.tensor(imagen_normalizada_squeezed, dtype=torch.float32)\n",
        "    imagen_tensor = imagen_tensor.unsqueeze(0).unsqueeze(0)\n",
        "    return imagen_tensor\n",
        "\n",
        "def predecir_neumonia(modelo, imagen_tensor):\n",
        "    modelo.eval()\n",
        "    with torch.no_grad():\n",
        "        salida = modelo(imagen_tensor)\n",
        "        _, prediccion = torch.max(salida, 1)\n",
        "    return prediccion.item()"
      ],
      "metadata": {
        "id": "R8sNhJ17SYVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defino el modelo\n",
        "class DenseLayer(nn.Sequential):\n",
        "    def __init__(self, in_channels, growth_rate):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.add_module('bn1', nn.BatchNorm2d(in_channels))\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv1', nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('bn2', nn.BatchNorm2d(4 * growth_rate))\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv2', nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "\n",
        "class DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, in_channels, growth_rate):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = DenseLayer(in_channels + i * growth_rate, growth_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "class TransitionLayer(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.add_module('bn', nn.BatchNorm2d(in_channels))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64, num_classes=2):\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('bn0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = DenseBlock(num_layers=num_layers, in_channels=num_features, growth_rate=growth_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = TransitionLayer(in_channels=num_features, out_channels=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        self.features.add_module('bn5', nn.BatchNorm2d(num_features))\n",
        "        self.features.add_module('relu5', nn.ReLU(inplace=True))\n",
        "        self.features.add_module('avgpool5', nn.AdaptiveAvgPool2d((1, 1)))\n",
        "\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.GroupNorm):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = torch.flatten(features, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "class CustomDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomDenseNet, self).__init__()\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        self.densenet.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        num_ftrs = self.densenet.classifier.in_features\n",
        "        self.densenet.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)"
      ],
      "metadata": {
        "id": "oEca6Wd9Evbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruebo el modelo con imágenes nuevas\n",
        "\n",
        "carpeta_principal_imagenes = \"/content/drive/MyDrive/Proyecto modulo 7/prueba/imagenes_nuevas/\"\n",
        "nombre_imagenes = [\"person1000_virus_1681.jpeg\", \"person1000_bacteria_2931.jpeg\"]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    modelo = CustomDenseNet(num_classes=2)\n",
        "    modelo.load_state_dict(torch.load('/content/drive/MyDrive/Proyecto modulo 7/prueba/mejor_modelo.pth'))\n",
        "    modelo.to(device)\n",
        "\n",
        "    resultados=[]\n",
        "\n",
        "    for nombre_imagen in nombre_imagenes:\n",
        "        imagen_tensor = procesar_imagen(nombre_imagen, carpeta_principal_imagenes)\n",
        "        if imagen_tensor is not None:\n",
        "            imagen_tensor = imagen_tensor.to(device)\n",
        "            prediccion = predecir_neumonia(modelo, imagen_tensor)\n",
        "            if prediccion == 1:\n",
        "                resultados.append(\"La imagen {} muestra signos de neumonía.\".format(nombre_imagen))\n",
        "            else:\n",
        "                resultados.append(\"La imagen {} no muestra signos de neumonía.\".format(nombre_imagen))\n",
        "        else:\n",
        "            resultados.append(\"Error: No se pudo procesar la imagen {}.\".format(nombre_imagen))\n",
        "\n",
        "    for resultado in resultados:\n",
        "        print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXvtV_qi-dhQ",
        "outputId": "393d82a8-9f59-4908-bb85-3469a0ba6bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La imagen person1000_virus_1681.jpeg muestra signos de neumonía.\n",
            "La imagen person1000_bacteria_2931.jpeg muestra signos de neumonía.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **API**"
      ],
      "metadata": {
        "id": "hkZZC0kDm1Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile api.py\n",
        "from flask import Flask, jsonify, request\n",
        "import cv2\n",
        "import torch\n",
        "from modelo import CustomDenseNet, procesar_imagen, predecir_neumonia  # Ajusta la importación según tu estructura de proyecto\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Cargar el modelo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "modelo = CustomDenseNet(num_classes=2)\n",
        "modelo.load_state_dict(torch.load('/content/drive/MyDrive/Proyecto modulo 7/prueba/mejor_modelo.pth'))\n",
        "modelo.to(device)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"No file provided\"}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    temp_image_path = \"temp_image.jpg\"\n",
        "    file.save(temp_image_path)\n",
        "    imagen = cv2.imread(temp_image_path)\n",
        "\n",
        "    imagen_tensor = procesar_imagen(imagen)\n",
        "    if imagen_tensor is None:\n",
        "        return jsonify({\"error\": \"Error processing the image\"}), 500\n",
        "\n",
        "    imagen_tensor = imagen_tensor.to(device)\n",
        "\n",
        "    prediccion = predecir_neumonia(modelo, imagen_tensor)\n",
        "\n",
        "    if prediccion == 1:\n",
        "        result = \"La imagen muestra signos de neumonía.\"\n",
        "    else:\n",
        "        result = \"La imagen no muestra signos de neumonía.\"\n",
        "\n",
        "    return jsonify({\"response\": result})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=8080, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBaNubl2-5P1",
        "outputId": "acb33fb3-5627-4337-bce5-4d9bf94ec49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api.py\n"
          ]
        }
      ]
    }
  ]
}