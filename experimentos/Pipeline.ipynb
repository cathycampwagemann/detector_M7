{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Flujo de trabajo para el dataset de radiografías de tórax**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AahA-raBoxn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Importar las librerías necesarias**"
      ],
      "metadata": {
        "id": "hLPk9ZLLpy8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtRiDUqFoxMm"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import re\n",
        "import cv2\n",
        "import joblib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Analizar la estructura del dataset y crear un dataframe**"
      ],
      "metadata": {
        "id": "Eb-PsP5Ip84F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "carpeta_principal_imagenes= '/content/drive/MyDrive/Proyecto modulo 7/data'\n",
        "\n",
        "for subcarpeta in os.listdir(carpeta_principal_imagenes):\n",
        "    sub_carpeta_imagenes = os.path.join(carpeta_principal_imagenes, subcarpeta)\n",
        "    if os.path.isdir(sub_carpeta_imagenes):\n",
        "        print(f\"Subcarpeta: {subcarpeta}\")\n",
        "\n",
        "        for sub_subcarpeta in os.listdir(sub_carpeta_imagenes):\n",
        "            sub_sub_carpeta_imagenes = os.path.join(sub_carpeta_imagenes, sub_subcarpeta)\n",
        "            if os.path.isdir(sub_sub_carpeta_imagenes):\n",
        "                print(f\"  Sub_subcarpeta: {sub_subcarpeta}\")\n",
        "\n",
        "                archivos = [f for f in os.listdir(sub_sub_carpeta_imagenes) if os.path.isfile(os.path.join(sub_sub_carpeta_imagenes, f))]\n",
        "                primeros_5_archivos = archivos[:5]\n",
        "\n",
        "                for archivo in primeros_5_archivos:\n",
        "                    print(f\"    Archivo: {archivo}\")"
      ],
      "metadata": {
        "id": "IWQBpe2rz4XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxt9klA3n-O",
        "outputId": "7ac79ad8-68ec-46e8-9c56-e9cd056cfca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Carpeta Categoría Sub categoría                 Nombre imagen  Ancho  Alto  \\\n",
            "0   train  neumonia         virus     person537_virus_1067.jpeg   1112   744   \n",
            "1   train  neumonia      bacteria    person53_bacteria_252.jpeg   1292   936   \n",
            "2   train  neumonia      bacteria  person537_bacteria_2263.jpeg   1216  1000   \n",
            "3   train  neumonia      bacteria  person540_bacteria_2272.jpeg   1088   736   \n",
            "4   train  neumonia      bacteria  person543_bacteria_2281.jpeg   1088   584   \n",
            "\n",
            "  Modo                                            Pixeles  \n",
            "0    L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "1    L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "2    L  [197, 203, 206, 203, 202, 206, 209, 210, 207, ...  \n",
            "3    L  [87, 82, 79, 80, 75, 65, 60, 62, 61, 65, 68, 6...  \n",
            "4    L  [62, 66, 66, 66, 72, 84, 90, 88, 72, 83, 99, 9...  \n"
          ]
        }
      ],
      "source": [
        "datos_imagenes = []\n",
        "\n",
        "for carpeta in ['train', 'val', 'test']:\n",
        "    sub_carpeta_imagenes = os.path.join(carpeta_principal_imagenes, carpeta)\n",
        "    if os.path.isdir(sub_carpeta_imagenes):\n",
        "        for categoria in ['neumonia', 'normal']:\n",
        "            sub_carpeta_categoria = os.path.join(sub_carpeta_imagenes, categoria)\n",
        "            if os.path.isdir(sub_carpeta_categoria):\n",
        "                for imagen in os.listdir(sub_carpeta_categoria):\n",
        "                    if imagen.endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                        ruta_imagen = os.path.join(sub_carpeta_categoria, imagen)\n",
        "\n",
        "                        with Image.open(ruta_imagen) as img:\n",
        "                            ancho, alto = img.size\n",
        "                            modo = img.mode\n",
        "                            pixeles = list(img.getdata())\n",
        "\n",
        "                        if 'virus' in imagen.lower():\n",
        "                            sub_categoria = 'virus'\n",
        "                        elif 'bacteria' in imagen.lower():\n",
        "                            sub_categoria = 'bacteria'\n",
        "                        else:\n",
        "                            sub_categoria = 'no hay bacteria ni virus'\n",
        "\n",
        "                        datos_imagenes.append([carpeta, categoria, sub_categoria, imagen, ancho, alto, modo,pixeles])\n",
        "\n",
        "columnas = ['Carpeta', 'Categoría', 'Sub categoría', 'Nombre imagen', 'Ancho', 'Alto', 'Modo','Pixeles']\n",
        "df = pd.DataFrame(datos_imagenes, columns=columnas)\n",
        "\n",
        "df.to_csv('image_data.csv', index=False)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_origen = '/content/image_data.csv'\n",
        "ruta_destino = '/content/drive/MyDrive/Proyecto modulo 7/image_data.csv'\n",
        "\n",
        "shutil.move(ruta_origen, ruta_destino)\n",
        "print(f\"Archivo movido a: {ruta_destino}\")"
      ],
      "metadata": {
        "id": "-VC_ApjcpWP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. División del conjunto de datos**"
      ],
      "metadata": {
        "id": "eQkLOHHoqHTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_incluidas = ['Carpeta', 'Categoría', 'Sub categoría', 'Nombre imagen', 'Ancho', 'Alto', 'Modo']\n",
        "\n",
        "df_train = df[df['Carpeta'] == 'train'][columnas_incluidas]\n",
        "df_test = df[df['Carpeta'] == 'test'][columnas_incluidas]\n",
        "df_val = df[df['Carpeta'] == 'val'][columnas_incluidas]"
      ],
      "metadata": {
        "id": "1PciHsLPpvel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Submuestreo de los datos de entrenamiento y test**"
      ],
      "metadata": {
        "id": "W6he2vTVqYdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_imagenes_neumonia=1500\n",
        "numero_imagenes_bacteria=int(total_imagenes_neumonia*0.55)\n",
        "numero_imagenes_virus=int(total_imagenes_neumonia*0.45)\n",
        "\n",
        "seleccion_imagenes_bacteria=df_train[df_train['Sub categoría']=='bacteria'].sample(n=numero_imagenes_bacteria,random_state=42)\n",
        "seleccion_imagenes_virus=df_train[df_train['Sub categoría']=='virus'].sample(n=numero_imagenes_virus,random_state=42)\n",
        "\n",
        "train_neumonia=pd.concat([seleccion_imagenes_bacteria,seleccion_imagenes_virus])\n",
        "\n",
        "train_normal=df_train[df_train['Categoría']=='normal']\n",
        "\n",
        "df_train_submuestreo=pd.concat([train_neumonia,train_normal])\n",
        "ruta_guardado = '/content/drive/MyDrive/Proyecto modulo 7/prueba/procesamiento_de_data/df_train_acotado.joblib'\n",
        "joblib.dump(df_train_submuestreo, ruta_guardado)\n",
        "\n",
        "df_train_submuestreo.head()"
      ],
      "metadata": {
        "id": "hma63hljqhST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_imagenes_neumonia_test=250\n",
        "numero_imagenes_bacteria_test=int(total_imagenes_neumonia_test*0.55)\n",
        "numero_imagenes_virus_test=int(total_imagenes_neumonia_test*0.45)\n",
        "\n",
        "seleccion_imagenes_bacteria_test=df_test[df_test['Sub categoría']=='bacteria'].sample(n=numero_imagenes_bacteria_test,random_state=42)\n",
        "seleccion_imagenes_virus_test=df_test[df_test['Sub categoría']=='virus'].sample(n=numero_imagenes_virus_test,random_state=42)\n",
        "\n",
        "test_neumonia=pd.concat([seleccion_imagenes_bacteria_test,seleccion_imagenes_virus_test])\n",
        "\n",
        "test_normal=df_test[df_test['Categoría']=='normal']\n",
        "\n",
        "df_test_submuestreo=pd.concat([test_neumonia,test_normal])\n",
        "ruta_guardado = '/content/drive/MyDrive/Proyecto modulo 7/prueba/df_test_acotado.joblib'\n",
        "joblib.dump(df_test_submuestreo, ruta_guardado)\n",
        "\n",
        "df_test_submuestreo.head()"
      ],
      "metadata": {
        "id": "NNeJB7B0qo04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Redimensionado de las imágenes y conversión a escala de grises**\n",
        "Función y carpetas definidas en notebook 3. Ingeniería de características"
      ],
      "metadata": {
        "id": "x_sPLmLnq19t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_submuestreo_con_ruta['Nueva Ruta Procesada']= df_train_submuestreo_con_ruta.apply(procesar_imagen, axis=1)\n",
        "df_test_submuestreo_con_ruta['Nueva Ruta Procesada']= df_test_submuestreo_con_ruta.apply(procesar_imagen, axis=1)\n",
        "df_val['Ruta de Imagen Procesada'] = df_val.apply(procesar_imagen, axis=1)"
      ],
      "metadata": {
        "id": "zTAKHmfArL3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Padding a las imágenes**\n",
        "Función y carpetas definidas en notebook 3. Ingeniería de características"
      ],
      "metadata": {
        "id": "UFxSKM-Urb0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths_train = df_train_submuestreo_con_ruta['Nueva Ruta Procesada'].tolist()\n",
        "image_paths_test = df_test_submuestreo_con_ruta['Nueva Ruta Procesada'].tolist()\n",
        "image_paths_val = df_val['Ruta de Imagen Procesada'].tolist()"
      ],
      "metadata": {
        "id": "f9rwPewgrhJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Redimensionamiento post padding**\n",
        "Función y carpetas definidas en notebook 3. Ingeniería de características"
      ],
      "metadata": {
        "id": "DWK-eqy6ryJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory_train = '/content/drive/MyDrive/Proyecto modulo 7/prueba/data_procesada/data_para_modelo/padded/train'\n",
        "image_paths_train = df_train_submuestreo_con_ruta['Nueva Ruta Procesada'].tolist()\n",
        "\n",
        "nueva_ruta_train=procesar_imagen_padding(image_paths_train, output_directory_train)\n",
        "\n",
        "output_directory_test = '/content/drive/MyDrive/Proyecto modulo 7/prueba/data_procesada/data_para_modelo/padded/test'\n",
        "image_paths_test = df_test_submuestreo_con_ruta['Nueva Ruta Procesada'].tolist()\n",
        "\n",
        "nueva_ruta_test=procesar_imagen_padding(image_paths_test, output_directory_test)\n",
        "\n",
        "output_directory_val = '/content/drive/MyDrive/Proyecto modulo 7/prueba/data_procesada/data_para_modelo/padded/val'\n",
        "image_paths_val = df_val['Ruta de Imagen Procesada'].tolist()\n",
        "\n",
        "nueva_ruta_val=procesar_imagen_padding(image_paths_val, output_directory_val)"
      ],
      "metadata": {
        "id": "TMWLHviWr3Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Separación de características**\n"
      ],
      "metadata": {
        "id": "Jmd_fln6uYKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train_submuestreo_con_ruta[['Ruta Redimensionada', 'Nombre imagen']]\n",
        "X_test = df_test_submuestreo_con_ruta[['Ruta Redimensionada', 'Nombre imagen']]\n",
        "X_val = df_val[['Ruta Redimensionada', 'Nombre imagen']]\n",
        "\n",
        "categoria_map = {'normal': 0, 'neumonia': 1}\n",
        "\n",
        "y_train = df_train_submuestreo_con_ruta['Categoría'].map(categoria_map)\n",
        "y_test = df_test_submuestreo_con_ruta['Categoría'].map(categoria_map)\n",
        "y_val = df_val['Categoría'].map(categoria_map)"
      ],
      "metadata": {
        "id": "FF_g9iI_uihk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Normalizar las imágenes**\n",
        "Función definidas en notebook 4. Modelo mejor versión"
      ],
      "metadata": {
        "id": "127kenBvyWg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_imgs = np.array([normalizar_imagenes(os.path.join(ruta_train, img)) for img in X_train['Ruta Redimensionada']])\n",
        "X_test_imgs = np.array([normalizar_imagenes(os.path.join(ruta_test, img)) for img in X_test['Ruta Redimensionada']])\n",
        "X_val_imgs = np.array([normalizar_imagenes(os.path.join(ruta_val, img)) for img in X_val['Ruta Redimensionada']])"
      ],
      "metadata": {
        "id": "xiyqigY8ycTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10. Definir y entrenar el modelo**\n",
        "Modelo definido DenseNet en notebook 4. Modelo mejor versión"
      ],
      "metadata": {
        "id": "UuLDRq3ZyvhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomDenseNet, self).__init__()\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        self.densenet.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        num_ftrs = self.densenet.classifier.in_features\n",
        "        self.densenet.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)\n",
        "\n",
        "model = CustomDenseNet(num_classes=2)\n",
        "\n",
        "num_epochs = 25\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def calculate_accuracy(y_pred, y_true):\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    correct = (predicted == y_true).sum().item()\n",
        "    total = y_true.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "best_val_accuracy = 0.0\n",
        "patience = 5\n",
        "no_improvement_count = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = inputs.unsqueeze(1)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        total_accuracy += calculate_accuracy(outputs, labels)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = total_accuracy / len(train_loader)\n",
        "\n",
        "    print(f\"Época {epoch+1}/{num_epochs}, Pérdida en conjunto de entrenamiento: {epoch_loss:.4f}, Precisión en conjunto de entrenamiento: {epoch_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "BgturDvDy-tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11. Evaluar el modelo**"
      ],
      "metadata": {
        "id": "eocbTOuezScC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_running_loss = 0.0\n",
        "        test_total_accuracy = 0.0\n",
        "\n",
        "        for test_inputs, test_labels in test_loader:\n",
        "            test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
        "            test_inputs = test_inputs.unsqueeze(1)\n",
        "\n",
        "            test_outputs = model(test_inputs)\n",
        "            test_loss = criterion(test_outputs, test_labels)\n",
        "            test_running_loss += test_loss.item()\n",
        "            test_total_accuracy += calculate_accuracy(test_outputs, test_labels)\n",
        "\n",
        "        test_epoch_loss = test_running_loss / len(test_loader)\n",
        "        test_epoch_accuracy = test_total_accuracy / len(test_loader)\n",
        "\n",
        "        print(f\"Época {epoch+1}/{num_epochs}, Pérdida en conjunto de prueba: {test_epoch_loss:.4f}, Precisión en conjunto de prueba: {test_epoch_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "pb-1l4WKzV1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumen del flujo de trabajo**\n",
        "\n",
        "1. Importar las librerías necesarias\n",
        "2. Analizar la estructura del dataset y crear un dataframe\n",
        "3. División del conjunto de datos\n",
        "4. Submuestreo de los datos de entrenamiento y test\n",
        "5. Redimensionado de las imágenes y conversión a escala de grises\n",
        "6. Padding a las imágenes\n",
        "7. Redimensionamiento post padding\n",
        "8. Separación de características\n",
        "9. Normalizar las imágenes\n",
        "10. Definir y entrenar el modelo\n",
        "11. Evaluar el modelo"
      ],
      "metadata": {
        "id": "E4-wOFzKzf_N"
      }
    }
  ]
}